[
	{
		"id": 0,
		"title": "Investigating the effectiveness of tactile feedback for mobile touchscreens",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://dl.acm.org/doi/abs/10.1145/1357054.1357300"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen A Brewster",
				"Jody Johnston"
			],
			"year": "2008",
			"publication_date": "Apr 6",
			"book": "Proceedings of the SIGCHI conference on Human factors in computing systems",
			"pages": "1573-1582",
			"description": "This paper presents a study of finger-based text entry for mobile devices with touchscreens. Many devices are now coming to market that have no physical keyboards (the Apple iPhone being a very popular example). Touchscreen keyboards lack any tactile feedback and this may cause problems for entering text and phone numbers. We ran an experiment to compare devices with a physical keyboard, a standard touchscreen and a touchscreen with tactile feedback added. We tested this in both static and mobile environments. The results showed that the addition of tactile feedback to the touchscreen significantly improved finger-based text entry, bringing it close to the performance of a real physical keyboard. A second experiment showed that higher specification tactile actuators could improve performance even further. The results suggest that manufacturers should use tactile feedback in their touchscreen devices …",
			"citations": {
				"total": "531",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12306793499752662637&as_sdt=5"
			}
		}
	},
	{
		"id": 1,
		"title": "How important is the “mental map”?–an empirical investigation of a dynamic graph layout algorithm",
		"pdf": {
			"host": "[PDF] from springer.com",
			"link": "https://link.springer.com/chapter/10.1007/978-3-540-70904-6_19"
		},
		"data": {
			"authors": [
				"Helen C Purchase",
				"Eve Hoggan",
				"Carsten Görg"
			],
			"year": "2006",
			"publication_date": "Sept 18",
			"conference": "International Symposium on Graph Drawing",
			"pages": "184-195",
			"publisher": "Springer, Berlin, Heidelberg",
			"description": "While some research has been performed on the human understanding of static graph layout algorithms, dynamic graph layout algorithms have only recently been developed sufficiently to enable similar investigations. This paper presents the first empirical analysis of a dynamic graph layout algorithm, focusing on the assumption that maintaining the “mental map” between time-slices assists with the comprehension of the evolving graph. The results confirm this assumption with respect to some categories of tasks.",
			"citations": {
				"total": "199",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1318639355774838271&as_sdt=5"
			}
		}
	},
	{
		"id": 2,
		"title": "Audio or tactile feedback: Which modality when?",
		"pdf": {
			"host": "[PDF] from psu.edu",
			"link": "https://dl.acm.org/doi/abs/10.1145/1518701.1519045"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Andrew Crossan",
				"Stephen A Brewster",
				"Topi Kaaresoja"
			],
			"year": "2009",
			"publication_date": "Apr 4",
			"book": "Proceedings of the SIGCHI conference on human factors in computing systems",
			"pages": "2253-2256",
			"description": "When designing interfaces for mobile devices it is import-ant to take into account the variety of contexts of use. We present a study that examines how changing noise and dis-turbance in the environment affects user performance in a touchscreen typing task with the interface being presented through visual only, visual and tactile, or visual and audio feedback. The aim of the study is to show at what exact environmental levels audio or tactile feedback become inef-fective. The results show significant decreases in perform-ance for audio feedback at levels of 94dB and above as well as decreases in performance for tactile feedback at vibration levels of 9.18 g/s. These results suggest that at these levels, feedback should be presented by a different modality. These findings will allow designers to take advantage of sensor enabled mobile devices to adapt the provided feed-back to the user's current context.",
			"citations": {
				"total": "118",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14530632110332439107&as_sdt=5"
			}
		}
	},
	{
		"id": 3,
		"title": "Designing audio and tactile crossmodal icons for mobile devices",
		"pdf": {
			"host": "[PDF] from gla.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/1322192.1322222"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen Brewster"
			],
			"year": "2007",
			"publication_date": "Nov 12",
			"book": "Proceedings of the 9th international conference on Multimodal interfaces",
			"pages": "162-169",
			"description": "This paper reports an experiment into the design of crossmodal icons which can provide an alternative form of output for mobile devices using audio and tactile modalities to communicate information. A complete set of crossmodal icons was created by encoding three dimensions of information in three crossmodal auditory/tactile parameters. Earcons were used for the audio and Tactons for the tactile crossmodal icons. The experiment investigated absolute identification of audio and tactile crossmodal icons when a user is trained in one modality and tested in the other (and given no training in the other modality) to see if knowledge could be transferred between modalities. We also compared performance when users were static and mobile to see any effects that mobility might have on recognition of the cues. The results showed that if participants were trained in sound with Earcons and then tested with the same …",
			"citations": {
				"total": "115",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17448212167267286988&as_sdt=5"
			}
		}
	},
	{
		"id": 4,
		"title": "Eco-feedback on the go: Motivating energy awareness",
		"pdf": {
			"host": "[PDF] from diva-portal.org",
			"link": "https://ieeexplore.ieee.org/abstract/document/5744061/"
		},
		"data": {
			"authors": [
				"Anna Spagnolli",
				"Nicola Corradi",
				"Luciano Gamberini",
				"Eve Hoggan",
				"Giulio Jacucci",
				"Cecilia Katzeff",
				"Loove Broms",
				"Li Jonsson"
			],
			"year": "2011",
			"publication_date": "Apr 7",
			"journal": "Computer",
			"volume": "44",
			"issue": "5",
			"pages": "38-45",
			"publisher": "IEEE",
			"description": "The EnergyLife mobile interface incorporates lessons from environmental psychology and feedback intervention to relay information from appliance sensors, offering a gaming environment that rewards users for decreased electricity consumption.",
			"citations": {
				"total": "110",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14596474917929966053&as_sdt=5"
			}
		}
	},
	{
		"id": 5,
		"title": "Mobile multi-actuator tactile displays",
		"pdf": {
			"host": "[PDF] from nozdr.ru",
			"link": "https://link.springer.com/chapter/10.1007/978-3-540-76702-2_4"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Sohail Anwar",
				"Stephen A Brewster"
			],
			"year": "2007",
			"publication_date": "Nov 29",
			"conference": "International Workshop on Haptic and Audio Interaction Design",
			"pages": "22-33",
			"publisher": "Springer, Berlin, Heidelberg",
			"description": "The potential of using the sense of touch to communicate information in mobile devices is receiving more attention because of the limitations of graphical displays in such situations. However, most applications only use a single actuator to present vibrotactile information. In an effort to create richer tactile feedback and mobile applications that make use of the entire hand and multiple fingers as opposed to a single fingertip, this paper presents the results of two experiments investigating the perception and application of multi-actuator tactile displays situated on a mobile device. The results of these experiments show that an identification rate of over 87% can be achieved when two dimensions of information are encoded in Tactons using rhythm and location. They also show that location produces 100% recognition rates when using actuators situated on the mobile device at the lower thumb, upper thumb, index …",
			"citations": {
				"total": "109",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=553208478717560812&as_sdt=5"
			}
		}
	},
	{
		"id": 6,
		"title": "Tailoring feedback to users’ actions in a persuasive game for household electricity conservation",
		"pdf": {
			"host": "[PDF] from helsinki.fi",
			"link": "https://link.springer.com/chapter/10.1007/978-3-642-31037-9_9"
		},
		"data": {
			"authors": [
				"Luciano Gamberini",
				"Anna Spagnolli",
				"Nicola Corradi",
				"Giulio Jacucci",
				"Giovanni Tusa",
				"Topi Mikkola",
				"Luca Zamboni",
				"Eve Hoggan"
			],
			"year": "2012",
			"publication_date": "June 6",
			"conference": "International conference on persuasive technology",
			"pages": "100-111",
			"publisher": "Springer, Berlin, Heidelberg",
			"description": "Recent work has begun to focus on the use of games as a platform for energy awareness and eco-feedback research. While technical advancements (wireless sensors, fingerprinting) make timely and tailored feedback an objective within easy reach, we argue that taking into account the users’ own personal consumption behavior and tailoring feedback accordingly is a key requirement and a harder challenge. We present a first attempt in this direction, EnergyLife, which is designed to support the users’ actions and embeds contextualized feedback triggered by specific actions of the user, called ‘smart advice’. We conclude by showing the results of a four-month trial with four households that returned promising results on the effectiveness and acceptance of this feature.",
			"citations": {
				"total": "91",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=925408781399081483&as_sdt=5"
			}
		}
	},
	{
		"id": 7,
		"title": "From space to stage: How interactive screens will change urban life",
		"pdf": {
			"host": null,
			"link": "https://ieeexplore.ieee.org/abstract/document/5766075/"
		},
		"data": {
			"authors": [
				"Kai Kuikkaniemi",
				"Giulio Jacucci",
				"Marko Turpeinen",
				"Eve Hoggan",
				"Jörg Müller"
			],
			"year": "2011",
			"publication_date": "May 12",
			"journal": "Computer",
			"volume": "44",
			"issue": "6",
			"pages": "40-47",
			"publisher": "IEEE",
			"description": "Framed digital displays will soon give way to walls and facades that creatively motivate individual and group interaction. A stage serves as an apt metaphor to explore the ways in which these ubiquitous screens can transform passive viewing into an involved performance.",
			"citations": {
				"total": "84",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17992844503482106569&as_sdt=5"
			}
		}
	},
	{
		"id": 8,
		"title": "New parameters for tacton design",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/1240866.1241017"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen Brewster"
			],
			"year": "2007",
			"publication_date": "Apr 28",
			"book": "CHI'07 Extended Abstracts on Human Factors in Computing Systems",
			"pages": "2417-2422",
			"description": "Tactons (tactile icons) are structured vibrotactile messages which can be used for non-visual information presentation. Information can be encoded in a set of Tactons by manipulating parameters available in the tactile domain. One limitation is the number of available usable parameters and research is ongoing to find further effective ones. This paper reports an experiment investigating different techniques (amplitude modulation, frequency, and waveform) for creating texture as a parameter for use in Tacton design. The results of this experiment show recognition rates of 94% for waveform, 81% for frequency, and 61% for amplitude modulation, indicating that a more effective way to create Tactons using the texture parameter is to employ different waveforms to represent roughness. These results will aid designers in creating more effective and usable Tactons.",
			"citations": {
				"total": "80",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16455904427383534221&as_sdt=5"
			}
		}
	},
	{
		"id": 9,
		"title": "A study of mobile mood awareness and communication through MobiMood",
		"pdf": {
			"host": "[PDF] from psu.edu",
			"link": "https://dl.acm.org/doi/abs/10.1145/1868914.1868933"
		},
		"data": {
			"authors": [
				"Karen Church",
				"Eve Hoggan",
				"Nuria Oliver"
			],
			"year": "2010",
			"publication_date": "Oct 16",
			"book": "Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries",
			"pages": "128-137",
			"description": "Recent research shows that there has been increased interest in investigating the role of mood and emotions in the HCI domain. Our moods, however, are complex. They are affected by many dynamic factors and can change multiple times throughout each day. Furthermore, our mood can have significant implications in terms of our experiences, our actions and most importantly on our interactions with other people. We have developed MobiMood, a proof-of-concept social mobile application that enables groups of friends to share their moods with each other. In this paper, we present the results of an exploratory field study of MobiMood, focusing on explicit mood sharing in-situ. Our results highlight that certain contextual factors had an effect on mood and the interpretation of moods. Furthermore, mood sharing and mood awareness appear to be good springboards for conversations and increased communication …",
			"citations": {
				"total": "70",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7396290318261243665&as_sdt=5"
			}
		}
	},
	{
		"id": 10,
		"title": "Multi-touch rotation gestures: Performance and ergonomics",
		"pdf": {
			"host": "[PDF] from st-andrews.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/2470654.2481423"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"John Williamson",
				"Antti Oulasvirta",
				"Miguel Nacenta",
				"Per Ola Kristensson",
				"Anu Lehtiö"
			],
			"year": "2013",
			"publication_date": "Apr 27",
			"book": "Proceedings of the Sigchi conference on human factors in computing systems",
			"pages": "3047-3050",
			"description": "Rotations performed with the index finger and thumb involve some of the most complex motor action among common multi-touch gestures, yet little is known about the factors affecting performance and ergonomics. This note presents results from a study where the angle, direction, diameter, and position of rotations were systematically manipulated. Subjects were asked to perform the rotations as quickly as possible without losing contact with the display, and were allowed to skip rotations that were too uncomfortable. The data show surprising interaction effects among the variables, and help us identify whole categories of rotations that are slow and cumbersome for users.",
			"citations": {
				"total": "69",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4472879280428655262&as_sdt=5"
			}
		}
	},
	{
		"id": 11,
		"title": "Crossmodal congruence: the look, feel and sound of touchscreen widgets",
		"pdf": {
			"host": "[PDF] from glasgow.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/1452392.1452423"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Topi Kaaresoja",
				"Pauli Laitinen",
				"Stephen Brewster"
			],
			"year": "2008",
			"publication_date": "Oct 20",
			"book": "Proceedings of the 10th international conference on Multimodal interfaces",
			"pages": "157-164",
			"description": "Our research considers the following question: how can visual, audio and tactile feedback be combined in a congruent manner for use with touchscreen graphical widgets? For example, if a touchscreen display presents different styles of visual buttons, what should each of those buttons feel and sound like? This paper presents the results of an experiment conducted to investigate methods of congruently combining visual and combined audio/tactile feedback by manipulating the different parameters of each modality. The results indicate trends with individual visual parameters such as shape, size and height being combined congruently with audio/tactile parameters such as texture, duration and different actuator technologies. We draw further on the experiment results using individual quality ratings to evaluate the perceived quality of our touchscreen buttons then reveal a correlation between perceived quality and …",
			"citations": {
				"total": "67",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15451970031178132817&as_sdt=5"
			}
		}
	},
	{
		"id": 12,
		"title": "Information‐seeking behaviors of computer scientists: Challenges for electronic literature search tools",
		"pdf": {
			"host": "[PDF] from wiley.com",
			"link": "https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/meet.14505001041"
		},
		"data": {
			"authors": [
				"Kumaripaba Athukorala",
				"Eve Hoggan",
				"Anu Lehtiö",
				"Tuukka Ruotsalo",
				"Giulio Jacucci"
			],
			"year": "2013",
			"journal": "Proceedings of the American Society for Information Science and Technology",
			"volume": "50",
			"issue": "1",
			"pages": "1-11",
			"publisher": "Wiley Subscription Services, Inc., A Wiley Company",
			"description": "Since the recent emergence of electronic literature resources, researchers have begun to adopt new information‐seeking practices. The purpose of this research is to investigate the information needs and searching behaviors of researchers, and their implications for electronic literature search tools. We conducted mixed‐method case studies involving interviews, diary logs, and observations of computer scientists followed by a web‐based survey to validate our findings. The results show that computer science researchers have the following main purposes for seeking information: keeping up to date, exploring new topics, reviewing literature, collaborating, preparing lectures, and recommending material for students. We found that keeping up to date with research is the most frequent purpose and exploring unfamiliar research areas is the most difficult. Furthermore, we found that literature searching is a collaborative …",
			"citations": {
				"total": "57",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13997460072083073593&as_sdt=5"
			}
		}
	},
	{
		"id": 13,
		"title": "Multi-touch pinch gestures: Performance and ergonomics",
		"pdf": {
			"host": "[PDF] from st-andrews.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/2512349.2512817"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Miguel Nacenta",
				"Per Ola Kristensson",
				"John Williamson",
				"Antti Oulasvirta",
				"Anu Lehtiö"
			],
			"year": "2013",
			"publication_date": "Oct 6",
			"book": "Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces",
			"pages": "219-222",
			"description": "Multi-touch gestures are prevalent interaction techniques for many different types of devices and applications. One of the most common gestures is the pinch gesture, which involves the expansion or contraction of a finger spread. There are multiple uses for this gesture--zooming and scaling being the most common--but little is known about the factors affecting performance and ergonomics of the gesture motion itself. In this note, we present the results from a study where we manipulated angle, direction, distance, and position of two-finger pinch gestures. The study provides insight into how variables interact with each other to affect performance and how certain combinations of pinch gesture characteristics can result in uncomfortable or difficult pinch gestures. Our results can help designers select faster pinch gestures and avoid difficult pinch tasks.",
			"citations": {
				"total": "48",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15002155944488641699&as_sdt=5"
			}
		}
	},
	{
		"id": 14,
		"title": "Mapping information to audio and tactile icons",
		"pdf": {
			"host": "[PDF] from core.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/1647314.1647382"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Roope Raisamo",
				"Stephen A Brewster"
			],
			"year": "2009",
			"publication_date": "Nov 2",
			"book": "Proceedings of the 2009 international conference on Multimodal interfaces",
			"pages": "327-334",
			"description": "We report the results of a study focusing on the meanings that can be conveyed by audio and tactile icons. Our research considers the following question: how can audio and tactile icons be designed to optimise congruence between crossmodal feedback and the type of information this feedback is intended to convey? For example, if we have a set of system warnings, confirmations, progress up-dates and errors: what audio and tactile representations best match the information or type of message? Is one modality more appropriate at presenting certain types of information than the other modality? The results of this study indicate that certain parameters of the audio and tactile modalities such as rhythm, texture and tempo play an important role in the creation of congruent sets of feedback when given a specific type of information to transmit. We argue that a combination of audio or tactile parameters derived from our …",
			"citations": {
				"total": "44",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15743173863907549702&as_sdt=5"
			}
		}
	},
	{
		"id": 15,
		"title": "Crossmodal icons for information display",
		"pdf": {
			"host": "[PDF] from gla.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/1125451.1125619"
		},
		"data": {
			"authors": [
				"Eve E Hoggan",
				"Stephen A Brewster"
			],
			"year": "2006",
			"publication_date": "Apr 21",
			"book": "CHI'06 extended abstracts on Human factors in computing systems",
			"pages": "857-862",
			"description": "This paper describes a novel form of display using crossmodal output. A crossmodal icon is an abstract icon that can be instantiated in one of two equivalent forms (auditory or tactile). These can be used in interfaces as a means of non-visual output. This paper discusses how crossmodal icons can be constructed and the potential benefits they bring to mobile human computer interfaces.",
			"citations": {
				"total": "44",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=937383493386940989&as_sdt=5"
			}
		}
	},
	{
		"id": 16,
		"title": "Pressages: augmenting phone calls with non-verbal messages",
		"pdf": {
			"host": "[PDF] from academia.edu",
			"link": "https://dl.acm.org/doi/abs/10.1145/2380116.2380185"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Craig Stewart",
				"Laura Haverinen",
				"Giulio Jacucci",
				"Vuokko Lantz"
			],
			"year": "2012",
			"publication_date": "Oct 7",
			"book": "Proceedings of the 25th annual ACM symposium on User interface software and technology",
			"pages": "555-562",
			"description": "ForcePhone is a mobile synchronous haptic communication system. During phone calls, users can squeeze the side of the device and the pressure level is mapped to vibrations on the recipient's device. The pressure/vibrotactile messages supported by ForcePhone are called pressages. Using a lab-based study and a small field study, this paper addresses the following questions: how can haptic interpersonal communication be integrated into a standard mobile device? What is the most appropriate feedback design for pressages? What types of non-verbal cues can be represented by pressages? Do users make use of pressages during their conversations? The results of this research indicate that such a system has value as a communication channel in real-world settings with users expressing greetings, presence and emotions through pressages.",
			"citations": {
				"total": "42",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2216708117292008511&as_sdt=5"
			}
		}
	},
	{
		"id": 17,
		"title": "Electrostatic modulated friction as tactile feedback: Intensity perception",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://link.springer.com/chapter/10.1007/978-3-642-31401-8_54"
		},
		"data": {
			"authors": [
				"Dinesh Wijekoon",
				"Marta E Cecchinato",
				"Eve Hoggan",
				"Jukka Linjama"
			],
			"year": "2012",
			"publication_date": "June 13",
			"conference": "International Conference on Human Haptic Sensing and Touch Enabled Computer Applications",
			"pages": "613-624",
			"publisher": "Springer, Berlin, Heidelberg",
			"description": "We describe the preliminary results from an experiment investigating the perceived intensity of modulated friction created by electrostatic force, or electrovibration. A prototype experimental system was created to evaluate user perception of sinusoidal electrovibration stimuli on a flat surface emulating a touch screen interface. We introduce a fixed 6-point Effect Strength Subjective Index (ESSI) as a measure of generic sensation intensity, and compare it with an open magnitude scale. The results of the experiment indicate that there are significant correlations between intensity perception and signal amplitude, and the highest sensitivity was found at a frequency of 80 Hz. The subjective results show that the users perceived the electrovibration stimuli as pleasant and a useful means of feedback for touchscreens.",
			"citations": {
				"total": "40",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11236638549650272325&as_sdt=5"
			}
		}
	},
	{
		"id": 18,
		"title": "Crosstrainer: testing the use of multimodal interfaces in situ",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://dl.acm.org/doi/abs/10.1145/1753326.1753378"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen A Brewster"
			],
			"year": "2010",
			"publication_date": "Apr 10",
			"book": "Proceedings of the SIGCHI conference on human factors in computing systems",
			"pages": "333-342",
			"description": "We report the results of an exploratory 8-day field study of CrossTrainer: a mobile game with crossmodal audio and tactile feedback. Our research focuses on the longitudinal effects on performance with audio and tactile feedback, the impact of context such as location and situation on performance and personal modality preference. The results of this study indicate that crossmodal feedback can aid users in entering answers quickly and accurately using a variety of different widgets. Our study shows that there are times when audio is more appropriate than tactile and vice versa and for this reason devices should support both tactile and audio feedback to cover the widest range of environments, user preference, locations and tasks.",
			"citations": {
				"total": "40",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7159337120841602734&as_sdt=5"
			}
		}
	},
	{
		"id": 19,
		"title": "The meaning of the virtual M idas touch: An ERP study in economic decision making",
		"pdf": {
			"host": "[PDF] from hope.ac.uk",
			"link": "https://onlinelibrary.wiley.com/doi/abs/10.1111/psyp.12361"
		},
		"data": {
			"authors": [
				"Michiel M Spapé",
				"Eve E Hoggan",
				"Giulio Jacucci",
				"Niklas Ravaja"
			],
			"year": "2015",
			"publication_date": "Mar",
			"journal": "Psychophysiology",
			"volume": "52",
			"issue": "3",
			"pages": "378-387",
			"description": "The Midas touch refers to the altruistic effects of a brief touch. Though these effects have often been replicated, they remain poorly understood. We investigate the psychophysiology of the effect using remotely transmitted, precisely timed, tactile messages in an economic decision‐making game called Ultimatum. Participants were more likely to accept offers after receiving a remotely transmitted touch. Furthermore, we found distinct effects of touch on event‐related potentials evoked by (a) feedback regarding accepted and rejected offers, (b) decision cues related to proposals, and (c) the haptic and auditory cues themselves. In each case, a late positive effect of touch was observed and related to the P3. Given the role of the P3 in memory‐related functions, the results indicate an indirect relationship between touch and generosity that relies on memory. This hypothesis was further tested and confirmed in the positive …",
			"citations": {
				"total": "36",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11503460867622078308&as_sdt=5"
			}
		}
	},
	{
		"id": 20,
		"title": "T-Bars: towards tactile user interfaces for mobile touchscreens",
		"pdf": {
			"host": "[PDF] from glasgow.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/1409240.1409301"
		},
		"data": {
			"authors": [
				"Malcolm Hall",
				"Eve Hoggan",
				"Stephen Brewster"
			],
			"year": "2008",
			"publication_date": "Sept 2",
			"book": "Proceedings of the 10th international conference on Human computer interaction with mobile devices and services",
			"pages": "411-414",
			"description": "Mobile device user interface elements tend to be based on desktop widgets that were not originally intended for small screen finger-based interfaces. Mobile usage scenarios afford many completely different interactions, so should be designed accordingly. This paper presents a new type of widget, the T-Bar, designed specifically for finger-based touchscreen interfaces using tactile feedback. Using the tactile feedback for orientation, the user's fingertip is guided along the T-Bar until an item is successfully selected. This paper offers observations on our finger-based touchscreen widget and two applications of the T-Bar widget. Both, File-o-Feel and Touch'n'Twist are multi-touch information browsing applications that deviate from traditional desktop GUI paradigms and are tailored for fingertip input where all interaction takes place through the use of T-Bars; eliminating the need for any other widgets.",
			"citations": {
				"total": "36",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15757885874759169771&as_sdt=5"
			}
		}
	},
	{
		"id": 21,
		"title": "The effect of tactile feedback latency in touchscreen interaction",
		"pdf": {
			"host": null,
			"link": "https://ieeexplore.ieee.org/abstract/document/5945463/"
		},
		"data": {
			"authors": [
				"Topi Kaaresoja",
				"Emilia Anttila",
				"Eve Hoggan"
			],
			"year": "2011",
			"publication_date": "June 21",
			"conference": "2011 IEEE World Haptics Conference",
			"pages": "65-70",
			"publisher": "IEEE",
			"description": "Touchscreens are becoming more and more popular, especially in mobile devices. There is also clear evidence of the benefits of tactile feedback in touchscreen interaction. However, the effect of the evident latency in interaction has been completely neglected in earlier investigations of touchscreen interaction. In this study we examined the effect of tactile feedback latencies on the usability of a touchscreen keypad. We used a realistic use case for number and character keypads; users entered three-number sequences and short sentences using the virtual buttons on the touch display. The experiments differed from each other in terms of the tactile feedback type (press-only or for press and release) and the keypad layout (number or QWERTY). The results were unexpected, but consistent in all three experiments: The performance did not drop significantly within the latency values used. However, the users evaluated …",
			"citations": {
				"total": "32",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2907979564440569989&as_sdt=5"
			}
		}
	},
	{
		"id": 22,
		"title": "Reach out and touch me: Effects of four distinct haptic technologies on affective touch in virtual reality",
		"pdf": {
			"host": "[PDF] from helsinki.fi",
			"link": "https://dl.acm.org/doi/abs/10.1145/2993148.2993171"
		},
		"data": {
			"authors": [
				"Imtiaj Ahmed",
				"Ville Harjunen",
				"Giulio Jacucci",
				"Eve Hoggan",
				"Niklas Ravaja",
				"Michiel M Spapé"
			],
			"year": "2016",
			"publication_date": "Oct 31",
			"book": "Proceedings of the 18th ACM International Conference on Multimodal Interaction",
			"pages": "341-348",
			"description": "Virtual reality presents an extraordinary platform for multimodal communication. Haptic technologies have been shown to provide an important contribution to this by facilitating co-presence and allowing affective communication. However, the findings of the affective influences rely on studies that have used myriad different types of haptic technology, making it likely that some forms of tactile feedback are more efficient in communicating emotions than others. To find out whether this is true and which haptic technologies are most effective, we measured user experience during a communication scenario featuring an affective agent and interpersonal touch in virtual reality. Interpersonal touch was simulated using two types of vibrotactile actuators and two types of force feedback mechanisms. Self-reports of subjective experience of the agent’s touch and emotions were obtained. The results revealed that, regardless of …",
			"citations": {
				"total": "26",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15488127734828936521&as_sdt=5"
			}
		}
	},
	{
		"id": 23,
		"title": "Situating wearables: Smartwatch use in context",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://dl.acm.org/doi/abs/10.1145/3025453.3025993"
		},
		"data": {
			"authors": [
				"Donald McMillan",
				"Barry Brown",
				"Airi Lampinen",
				"Moira McGregor",
				"Eve Hoggan",
				"Stefania Pizza"
			],
			"year": "2017",
			"publication_date": "May 2",
			"book": "Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
			"pages": "3582-3594",
			"description": "Drawing on 168 hours of video recordings of smartwatch use, this paper studies how context influences smartwatch use. We explore the effects of the presence of others, activity, location and time of day on 1,009 instances of use. Watch interaction is significantly shorter when in conversation than when alone. Activity also influences watch use with significantly longer use while eating than when socialising or performing domestic tasks. One surprising finding is that length of use is similar at home and work. We note that usage peaks around lunchtime, with an average of 5.3 watch uses per hour throughout a day. We supplement these findings with qualitative analysis of the videos, focusing on how use is modified by the presence of others, and the lack of impact of watch glances on conversation. Watch use is clearly a context-sensitive activity and in discussion we explore how smartwatches could be designed taking …",
			"citations": {
				"total": "24",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13802944034884076132&as_sdt=5"
			}
		}
	},
	{
		"id": 24,
		"title": "Physical versus digital sticky notes in collaborative ideation",
		"pdf": {
			"host": "[HTML] from springer.com",
			"link": "https://link.springer.com/article/10.1007/s10606-018-9325-1"
		},
		"data": {
			"authors": [
				"Mads Møller Jensen",
				"Sarah-Kristin Thiel",
				"Eve Hoggan",
				"Susanne Bødker"
			],
			"year": "2018",
			"publication_date": "Dec",
			"journal": "Computer Supported Cooperative Work (CSCW)",
			"volume": "27",
			"issue": "3",
			"pages": "609-645",
			"publisher": "Springer Netherlands",
			"description": "In this paper, we compare the use of physical and digital sticky notes in collaborative ideation. Inspired by a case study in a design company, we focus on a collaborative ideation task, which is often part of pair-wise brainstorming in design. For comparison and to focus on the different materiality, we developed a digital sticky notes setup designed to be as close to the physical setup as possible, not adding any advanced digital features, even though technology has reached a stage where more sophisticated use of digital sticky notes on digital boards is possible. In this paper, we present a study of ideation among pairs of experienced sticky note users. The ideation sessions were video recorded and analyzed to focus on how collaboration is supported across the two setups. Based on quantitative analyses of the participants’ interactions with the artefacts, talking patterns, position and attention during the …",
			"citations": {
				"total": "22",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13785748946720617096&as_sdt=5"
			}
		}
	},
	{
		"id": 25,
		"title": "Playing with tactile feedback latency in touchscreen interaction: Two approaches",
		"pdf": {
			"host": "[PDF] from springer.com",
			"link": "https://link.springer.com/chapter/10.1007/978-3-642-23771-3_42"
		},
		"data": {
			"authors": [
				"Topi Kaaresoja",
				"Eve Hoggan",
				"Emilia Anttila"
			],
			"year": "2011",
			"publication_date": "Sept 5",
			"conference": "IFIP Conference on Human-Computer Interaction",
			"pages": "554-571",
			"publisher": "Springer, Berlin, Heidelberg",
			"description": "A great deal of research has investigated the potential parameters of tactile feedback for virtual buttons. However, these studies do not take the possible effects of feedback latencies into account. Therefore, this research investigates the impact of tactile feedback delays on touchscreen keyboard usage. The first experiment investigated four tactile feedback delay conditions during a number entry task. The results showed that keypads with a constant delay (18 ms) and the smallest feedback delay variation were faster to use and produced less errors compared to conditions with wider delay variability. The experiment also produced an unexpected finding – users seemed to perceive buttons with longer delays as heavier, with a need for greater force when pressing. Therefore another experiment was conducted to investigate this phenomenon. Seven delay conditions were tested using a magnitude estimation …",
			"citations": {
				"total": "22",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=543242205258703007&as_sdt=5"
			}
		}
	},
	{
		"id": 26,
		"title": "Tactile displays",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "http://books.google.com/books?hl=en&lr=&id=NpldsRcAY9oC&oi=fnd&pg=PA339&dq=info:0mozrpTpHpkJ:scholar.google.com&ots=5umXoqpJ-y&sig=ugYLsJteas_DASrsdYIuhVjoGVQ"
		},
		"data": {
			"authors": [
				"Stephen A Brewster",
				"S Wall",
				"Lorna M Brown",
				"E Hoggan"
			],
			"year": "2008",
			"publication_date": "Sept 22",
			"journal": "The Engineering Handbook on Smart Technology for Aging, Disability and Independence",
			"pages": "339-352",
			"publisher": "John Wiley and Sons Inc.",
			"description": "The work presented in this chapter focuses on potential uses of tactile displays for visually impaired and older adults. According to the Royal National Institute for the Blind, UK (www. rnib. org) there are two million people in the UK with sight problems (with 378,000 registered blind), and 85% of these are over 65 years of age. The aging population in Western countries means that this group will form an increasing proportion of the whole population. According to estimates from the US Census Bureau’s International Database (in 2004), the proportion of those in the UK who are over 60 is expected to increase from 20% in the year 2000 to 27% by 2025. Gregor et al.[1] note that older people are a very diverse group, with a diverse range of abilities, and it is difficult to draw a simple profile or stereotype. The individual variability of physical, sensory, and cognitive functions increases with age, with many people facing multiple smaller declines. These factors mean that careful consideration is required to design effective user interfaces for these important and diverse groups.Tactile displays can offer an alternative channel through which to present information if other senses are impaired. The traditional use of encodings such as Braille is effective at presenting textual information nonvisually, but touch can also be used to present or enhance iconic and pictorial data for those whose sight is beginning to fade. Alternatively, for someone with hearing problems, touch can be used to present alarms or other messages that might otherwise be given in sound. One major benefit with the tactile modality is that it is private, unlike audio, which can be overheard by …",
			"citations": {
				"total": "17",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11033512961891330770&as_sdt=5"
			}
		}
	},
	{
		"id": 27,
		"title": "An exploration of inadvertent variations in mobile pressure input",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://dl.acm.org/doi/abs/10.1145/2371574.2371581"
		},
		"data": {
			"authors": [
				"Craig Stewart",
				"Eve Hoggan",
				"Laura Haverinen",
				"Hugues Salamin",
				"Giulio Jacucci"
			],
			"year": "2012",
			"publication_date": "Sept 21",
			"book": "Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services",
			"pages": "35-38",
			"description": "This paper reports the results of an exploratory study into inadvertent grip pressure changes on mobile devices with a focus on the differences between static lab-based and mobile walking environments. The aim of this research is to inform the design of more robust pressure input techniques that can accommodate dynamic mobile usage. The results of the experiment show that there are significant differences in grip pressure in static and walking conditions with high levels of pressure variation in both. By combining the pressure data with accelerometer data, we show that grip pressure is closely related to user movement.",
			"citations": {
				"total": "13",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4111442789003760925&as_sdt=5"
			}
		}
	},
	{
		"id": 28,
		"title": "Crossmodal spatial location: initial experiments",
		"pdf": {
			"host": "[PDF] from gla.ac.uk",
			"link": "https://dl.acm.org/doi/abs/10.1145/1182475.1182539"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen Brewster"
			],
			"year": "2006",
			"publication_date": "Oct 14",
			"book": "Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles",
			"pages": "469-472",
			"description": "This paper describes an alternative form of interaction for mobile devices using crossmodal output. The aim of our work is to investigate the equivalence of audio and tactile displays so that the same messages can be presented in one form or another. Initial experiments show that spatial location can be perceived as equivalent in both the auditory and tactile modalities Results show that participants are able to map presented 3D audio positions to tactile body positions on the waist most effectively when mobile and that there are significantly more errors made when using the ankle or wrist. This paper compares the results from both a static and mobile experiment on crossmodal spatial location and outlines the most effective ways to use this crossmodal output in a mobile context.",
			"citations": {
				"total": "13",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11457079691318095653&as_sdt=5"
			}
		}
	},
	{
		"id": 29,
		"title": "Mid-air haptics and displays: systems for un-instrumented mid-air interactions",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/2851581.2856464"
		},
		"data": {
			"authors": [
				"Sriram Subramanian",
				"Sue Ann Seah",
				"Hiroyuki Shinoda",
				"Eve Hoggan",
				"Loic Corenthy"
			],
			"year": "2016",
			"publication_date": "May 7",
			"book": "Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems",
			"pages": "3446-3452",
			"description": "A fundamental shift is underway in how we interact with our computers and devices. Touchless sensing products are being launched across consumer electronics, home, automotive and healthcare industries. Recent advances in haptics and display technologies has meant that interaction designers can also provide users with tactile feedback in mid-air AND display visual elements wherever the user needs them without in anyway instrumenting the user. The overarching goal of this workshop is to bring together a group of researchers spanning across multiple facets of exploring interactions with mid-air systems to discuss, explore, and outline research challenges for this novel area. We are especially interested in exploring how novel display and haptic technology provide users with more compelling and immersive experiences without instrumenting them in anyway.",
			"citations": {
				"total": "12",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12170346364139581210&as_sdt=5"
			}
		}
	},
	{
		"id": 30,
		"title": "Beyond generalization: research for the very particular",
		"pdf": {
			"host": "[PDF] from jovermeulen.com",
			"link": "https://dl.acm.org/doi/fullHtml/10.1145/3289425"
		},
		"data": {
			"authors": [
				"Olav W Bertelsen",
				"Susanne Bødker",
				"Eva Eriksson",
				"Eve Hoggan",
				"Jo Vermeulen"
			],
			"year": "2018",
			"publication_date": "Dec 21",
			"journal": "Interactions",
			"volume": "26",
			"issue": "1",
			"pages": "34-38",
			"publisher": "ACM",
			"description": "In this article, we discuss HCI research that does not aim for universal or generic solutions, but rather focuses on addressing the particular challenges of particular people in particular situations or activities. We clarify what we mean by design and research for the very particular with examples from industry and academic research, highlight benefits and potential problems, discuss our suggestions, and conclude with a list of open questions for HCI researchers to consider. The discussion presented here is a result of a series of debates at the Center for Participatory IT at Aarhus",
			"citations": {
				"total": "11",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15435759016018096084&as_sdt=5"
			}
		}
	},
	{
		"id": 31,
		"title": "Crossmodal audio and tactile interaction with mobile touchscreens",
		"pdf": {
			"host": "[PDF] from gla.ac.uk",
			"link": "https://www.igi-global.com/chapter/content/62347"
		},
		"data": {
			"authors": [
				"Eve Hoggan"
			],
			"year": "2012",
			"book": "Social and Organizational Impacts of Emerging Mobile Devices: Evaluating Use",
			"pages": "249-264",
			"publisher": "IGI Global",
			"description": "This article asserts that using crossmodal auditory and tactile interaction can aid mobile touchscreen users in accessing data non-visually and, by providing a choice of modalities, can help to overcome problems that occur in different mobile situations where one modality may be less suitable than another (Hoggan, 2010). By encoding data using the crossmodal parameters of audio and vibration, users can learn mappings and translate information between both modalities. In this regard, data may be presented to the most appropriate modality given the situation and surrounding environment.",
			"citations": {
				"total": "11",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16416822781027061964&as_sdt=5"
			}
		}
	},
	{
		"id": 32,
		"title": "Boxer: a multimodal collision technique for virtual objects",
		"pdf": {
			"host": "[PDF] from aalto.fi",
			"link": "https://dl.acm.org/doi/abs/10.1145/3136755.3136761"
		},
		"data": {
			"authors": [
				"Byungjoo Lee",
				"Qiao Deng",
				"Eve Hoggan",
				"Antti Oulasvirta"
			],
			"year": "2017",
			"publication_date": "Nov 3",
			"book": "Proceedings of the 19th ACM International Conference on Multimodal Interaction",
			"pages": "252-260",
			"description": "Virtual collision techniques are interaction techniques for invoking discrete events in a virtual scene, eg throwing, pushing, or pulling an object with a pointer. The conventional approach involves detecting collisions as soon as the pointer makes contact with the object. Furthermore, in general, motor patterns can only be adjusted based on visual feedback. The paper presents a multimodal technique based on the principle that collisions should be aligned with the most salient sensory feedback. Boxer (1) triggers a collision at the moment where the pointer's speed reaches a minimum after first contact and (2) is synchronized with vibrotactile stimuli presented to the hand controlling the pointer. Boxer was compared with the conventional technique in two user studies (with temporal pointing and virtual batting). Boxer improved spatial precision in collisions by 26.7% while accuracy was compromised under some task …",
			"citations": {
				"total": "10",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16963257146974953882&as_sdt=5"
			}
		}
	},
	{
		"id": 33,
		"title": "Haptic interfaces",
		"pdf": {
			"host": null,
			"link": "http://books.google.com/books?hl=en&lr=&id=vZjCAQAAQBAJ&oi=fnd&pg=PA342&dq=info:tQmUszIZia4J:scholar.google.com&ots=Ppnt9xMPPv&sig=vYdV9dDyIDedFYu4hANJBow4Aus"
		},
		"data": {
			"authors": [
				"Eve Hoggan"
			],
			"year": "2013",
			"publication_date": "July 31",
			"journal": "The Sage handbook of digital technology research",
			"pages": "342-358",
			"publisher": "Sage",
			"description": "The study of haptic interfaces is an everexpanding research area focusing on human touch and interaction with the environment through touch. The term haptic can be defined as ‘sensory and/or motor activity based in the skin, muscles, joints and tendons’(ISO, 2011 244: 1). The creation of haptic interfaces depends on an in-depth knowledge of the human body and its ability to sense touch and kinesthetic sensations. Our sense of touch is crucial in our everyday interactions with the world. For instance, when looking for an object in your pocket or bag without the use of vision, the haptic sense becomes the primary modality of use. Despite the fact that the haptic modality is an extremely rich bi-directional information channel, it is relatively underutilized in current interactive systems in comparison to the audio and visual modalities. For example, in terms of interface design, a large number of systems have moved away from mechanical buttons, switches and other widgets and have adopted",
			"citations": {
				"total": "9",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12576611139960703413&as_sdt=5"
			}
		}
	},
	{
		"id": 34,
		"title": "Squeeze vs. tilt: a comparative study using continuous tactile feedback",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/1979742.1979766"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Dari Trendafilov",
				"Teemu Ahmaniemi",
				"Roope Raisamo"
			],
			"year": "2011",
			"publication_date": "May 7",
			"book": "CHI'11 Extended Abstracts on Human Factors in Computing Systems",
			"pages": "1309-1314",
			"description": "This paper presents an investigation into the performance of squeezing as a manipulative interaction technique in comparison to tilting with an aim to answer two questions: is squeezing an effective input technique for mobile devices and can tactile feedback improve performance? The experiment results show that both input methods are viable but squeezing is significantly faster and more sustainable than tilting (with and without tactile feedback).",
			"citations": {
				"total": "6",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8132351192124068416&as_sdt=5"
			}
		}
	},
	{
		"id": 35,
		"title": "Some severe deficiencies of the input-output HCI-paradigm and their influence on practical design",
		"pdf": {
			"host": "[PDF] from auditorysigns.com",
			"link": "http://www.auditorysigns.com/kai/papers/Tuuri_etal_2009_Some_severe_deficiencies.pdf"
		},
		"data": {
			"authors": [
				"Kai Tuuri",
				"Antti Pirhonen",
				"Eve Hoggan"
			],
			"year": "2009",
			"journal": "Designing beyond the Product-Understanding Activity and User Experience in Ubiquitous Environments",
			"pages": "363-369",
			"description": "The Cartesian dichotomy of human mind and body has largely ruled the development of western thought. One effect of that Cartesian legacy is the tendency to conceive interaction between a user and smart device as being composed of different inputs and outputs. In many cases, this is a practical and highly appropriate approach to design interactive technology. We, however, argue that such an approach tends to put too much emphasis on the technical instrumentation that provides information for different senses, thus considering sensory modalities as independent ‘receiver modules’. Perception is not directly created on the basis of the physical origin of the sensation. Rather, we argue that it is based on sensory-motorically integrated gestalts. For instance, a haptic feedback experience can even take place in the presence of only visual or audio cues that become coupled with interaction [1, 2]. If the concept of haptic feedback is merely understood in terms of the sense of touch and its usage with the help of, eg force actuator technology, it could be argued that the choice of options in user interface design is severely narrowed, and may result in the inappropriate use of available technology. By discussing the design of haptic feedback for touch screen applications, this paper illustrates the deficiencies of the inputoutput paradigm. It also stresses the close coupling between perception and action, which is realised in the course of interaction in a way that does not justify splitting them conceptually when striving towards a deeper understanding about human-computer interaction.",
			"citations": {
				"total": "6",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5702726370787810426&as_sdt=5"
			}
		}
	},
	{
		"id": 36,
		"title": "Human-Computer Interaction INTERACT 2007",
		"pdf": {
			"host": null,
			"link": "http://scholar.google.com/scholar?cluster=2625976981945830462&hl=en&oi=scholarr"
		},
		"data": {
			"authors": [
				"Cécilia Baranauskas",
				"Julio Abascal"
			],
			"year": "2007",
			"publisher": "Springer-Verlag Berlin Heidelberg",
			"citations": {
				"total": "6",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2625976981945830462&as_sdt=5"
			}
		}
	},
	{
		"id": 37,
		"title": "Knobology 2.0: Giving shape to the haptic force feedback of interactive knobs",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/3266037.3271649"
		},
		"data": {
			"authors": [
				"Anke van Oosterhout",
				"Majken Kirkegård Rasmussen",
				"Eve Hoggan",
				"Miguel Bruns"
			],
			"year": "2018",
			"publication_date": "Oct 11",
			"book": "The 31st Annual ACM Symposium on User Interface Software and Technology Adjunct Proceedings",
			"pages": "197-199",
			"description": "We present six rotary knobs, each with a distinct shape, that provide haptic force feedback on rotation. The knob shapes were evaluated in relation to twelve haptic feedback stimuli. The stimuli were designed as a combination of the most relevant perceptual parameters of force feedback; acceleration, friction, detent amplitude and spacing. The results indicate that there is a relationship between the shape of a knob and its haptic feedback. The perceived functionality can be dynamically altered by changing its shape and haptic feedback. This work serves as basis for the design of dynamic interface controls that can adapt their shape and haptic feel to the content that is controlled. In our demonstration, we show the six distinct knobs shapes with the different haptic feedback stimuli. Attendees can experience the interaction with the different knob shapes in relation the stimuli and design stimuli with a graphical editor.",
			"citations": {
				"total": "5",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14980715432632314345&as_sdt=5"
			}
		}
	},
	{
		"id": 38,
		"title": "DynaKnob: combining haptic force feedback and shape change",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/3322276.3322321"
		},
		"data": {
			"authors": [
				"Anke van Oosterhout",
				"Eve Hoggan",
				"Majken Kirkegaard Rasmussen",
				"Miguel Bruns"
			],
			"year": "2019",
			"publication_date": "June 18",
			"book": "Proceedings of the 2019 on Designing Interactive Systems Conference",
			"pages": "963-974",
			"description": "Despite the advantages of tangible interaction, physical controls like knobs seem to be disappearing from a wide range of products in our everyday life. The work presented in this paper explores how physical controls can become dynamic, in terms of both shape, and haptic force feedback. The paper contains two strands of work: First, we present a study that explores the relationship between haptic force feedback and different knob shapes, evaluating twelve distinct haptic stimuli in relation to six widely used knob shapes. Second, based on the insights collected in the study, we present the design of DynaKnob, a shape changing knob that can change between four different knob shapes. DynaKnob illustrates how dynamic content control, can be combined with dynamic shape and force feedback. Both the study and the design of DynaKnob contribute to understanding how adaptive physical interface controls could …",
			"citations": {
				"total": "4",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12415793369217525434&as_sdt=5"
			}
		}
	},
	{
		"id": 39,
		"title": "Designing social mobile interfaces: experiences with MobiMood, a mobile mood sharing application",
		"pdf": {
			"host": "[PDF] from psu.edu",
			"link": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.2761&rep=rep1&type=pdf"
		},
		"data": {
			"authors": [
				"Karen Church",
				"Eve Hoggan",
				"Nuria Oliver"
			],
			"year": "2010",
			"publication_date": "Feb",
			"journal": "Workshop on Visual Interfaces to the Social and Semantic Web",
			"description": "The exploration of mood and emotions in HCI is emerging as an important field of research. Our moods are affected by many different factors and can change multiple times throughout each day. Furthermore, our moods can have significant implications on our social interactions and our willingness to interact with others. We have developed MobiMood, a novel proof-of-concept social mobile application that enables groups of friends to share their moods with each other. In this paper, we present some high level results of an exploratory field study of MobiMood and highlight key implications in the design of future social mobile interfaces.",
			"citations": {
				"total": "4",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15793597877183031696&as_sdt=5"
			}
		}
	},
	{
		"id": 40,
		"title": "An Exploration of Mobile Shape-Changing Textures",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/3024969.3024983"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Yi-Ta Hsieh",
				"Kalle Myllymaa",
				"Vuokko Lantz",
				"Johan Kildal",
				"Julian Eiler",
				"Giulio Jacucci"
			],
			"year": "2017",
			"publication_date": "Mar 20",
			"book": "Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction",
			"pages": "275-282",
			"description": "This paper describes the development and evaluation of Undulating Covers (UnCovers), mobile interfaces that can change their surface texture to transmit information. The Pin Array UnCover incorporates sinusoidal ridges controlled by servomotors, which can change their amplitude and granularity. The Mylar UnCover is a more organic interface that exploits the buckling properties of Mylar, using muscle wires, to change the texture granularity. The prototype development process and evaluations show that very low frequency texture changes, using amplitude or granularity, can be distinguished with high levels of accuracy. Since small changes are perceptible, it is possible to incorporate such interfaces into mobile devices without drastically increasing their size or actuation requirements. Finally, ratings from participants indicate that UnCovers would be appropriate for attention-grabbing, or caring and supportive …",
			"citations": {
				"total": "3",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10824121990176911546&as_sdt=5"
			}
		}
	},
	{
		"id": 41,
		"title": "Nonspeech auditory and crossmodal output",
		"pdf": {
			"host": null,
			"link": "https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.1201/b11963-ch-10&type=chapterpdf"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen Brewster"
			],
			"year": "2012",
			"publication_date": "May 1",
			"journal": "The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications",
			"pages": "211-236",
			"description": "Similarly, our sense of touch can also provide us with a vast amount of information. Geldard (1960) wrote:“for some kinds of messages the skin offers a valuable supplement to ears and eyes”(p. 1583). The skin offers a large display space, which can be used to display information (Geldard 1960). As the skin is often less engaged in other tasks than the eyes or ears, it is always ready to receive information (van Veen and van Erp 2000). Using the sense of touch enables subtle and private communication unlike sound. The combination of visual, tactile, and auditory feedback at the user interface is a powerful tool for interaction. In our everyday life, these primary senses combine to give complementary information about the world. Blattner and Dannenberg (1992) discuss some of the advantages of using this approach in multimedia or multimodal computer systems:“In our interaction with the world around us, we use …",
			"citations": {
				"total": "3",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9339716453996658675&as_sdt=5"
			}
		}
	},
	{
		"id": 42,
		"title": "Physical versus Digital Sticky Notes in Collaborative Ideation",
		"pdf": {
			"host": "[PDF] from eusset.eu",
			"link": "https://dl.eusset.eu/handle/20.500.12015/3137"
		},
		"data": {
			"authors": [
				"Mads Møller Jensen",
				"Sarah-Kristin Thiel",
				"Eve Hoggan",
				"Susanne Bødker"
			],
			"year": "2018",
			"journal": "Computer Supported Cooperative Work 27 (3-4)-ECSCW 2018: Proceedings of the 16th European Conference on Computer Supported Cooperative Work",
			"publisher": "Springer, London",
			"description": "In this paper, we compare the use of physical and digital sticky notes in collaborative ideation. Inspired by a case study in a design company, we focus on a collaborative ideation task, which is often part of pair-wise brainstorming in design. For comparison and to focus on the different materiality, we developed a digital sticky notes setup designed to be as close to the physical setup as possible, not adding any advanced digital features, even though technology has reached a stage where more sophisticated use of digital sticky notes on digital boards is possible. In this paper, we present a study of ideation among pairs of experienced sticky note users. The ideation sessions were video recorded and analyzed to focus on how collaboration is supported across the two setups. Based on quantitative analyses of the participants’ interactions with the artefacts, talking patterns, position and attention during the sessions, we qualify how the differences and similarities between the two setups have an impact on note handling, ideation techniques, group dynamics and socio-spatial configuration, e.g. the use of the room, the boards and tables. We conclude that, while the physical setup seems more appropriate for creating notes and posting notes, the digital setup invites more note interaction. Nevertheless, we did not find significant differences in the ideation outcome (e.g., number of notes created) or how participants collaborated between the two setups. Hence, we argue that collaborative ideation can successfully be supported in a digital setup as well. Consequently, we believe that the next step in a technological setup is not an either or, but should bring …",
			"citations": {
				"total": "2",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4566692605113555823&as_sdt=5"
			}
		}
	},
	{
		"id": 43,
		"title": "Somehow They Are Never Horny!",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/pdf/10.1145/3393914.3395877"
		},
		"data": {
			"authors": [
				"Gopinaath Kannabiran",
				"Eve Hoggan",
				"Lone Koefoed Hansen"
			],
			"year": "2020",
			"publication_date": "July 6",
			"book": "Companion Publication of the 2020 ACM Designing Interactive Systems Conference",
			"pages": "131-137",
			"description": "With this provocation, we argue that existing HCI discourses on ageing risk rendering older adults as asexual individuals through research writing. We begin by articulating how discursive subjectivities such as users, consumers, participants, etc. are constructed, maintained, and propagated as representations of other individuals/groups through HCI research. We build our argument with examples highlighting tropes that have led to marginalization of certain groups of individuals through research writing. Through our provocation, we argue for re-framing and exploring sexual wellbeing of older adults as a fundamental humans rights issue and social justice concern while designing technologies. We point to problematic assumptions, amplify concerns, and call for further HCI research on sexual needs, desires, and experiences of older adults.",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1147066964804891717&as_sdt=5"
			}
		}
	},
	{
		"id": 44,
		"title": "Reshaping Interaction with Rotary Knobs: Combining Form, Feel and Function",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/3357236.3395536"
		},
		"data": {
			"authors": [
				"Anke van Oosterhout",
				"Eve Hoggan"
			],
			"year": "2020",
			"publication_date": "July 3",
			"book": "Proceedings of the 2020 ACM Designing Interactive Systems Conference",
			"pages": "1973-1982",
			"description": "This paper presents an evaluation of DynaKnob: a dynamic rotary knob that uses the relationship between physical shape and haptic force feedback to provide feedback about its functionality. It has the ability to morph into four distinct shapes whilst providing dynamic haptic force feedback. We explore how shape change and haptic force feedback can improve interactions by evaluating the DynaKnob in terms of usability, user experience and performance. Additionally, we look at how interaction techniques are influenced by these modalities. Results indicate that multimodal cues provided by haptic force feedback and different shapes did not improve usability, since the visual feedback provided by the GUI dominated the evaluated context. However, both modalities had a positive effect on the user experience, and showed potential to improve the performance in terms of accuracy for non-visual interaction.",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1685872126467556616&as_sdt=5"
			}
		}
	},
	{
		"id": 45,
		"title": "Digitizing sticky notes",
		"pdf": {
			"host": null,
			"link": "https://www.sciencedirect.com/science/article/pii/B9780128165669000057"
		},
		"data": {
			"authors": [
				"Susanne Bødker",
				"Eve Hoggan",
				"Mads Møller Jensen",
				"Clemens Nylandsted Klokmose",
				"Roman Rädle",
				"Sarah-Kristin Thiel"
			],
			"year": "2020",
			"publication_date": "Jan 1",
			"book": "Sticky Creativity",
			"pages": "103-123",
			"publisher": "Academic Press",
			"description": "This chapter discusses the difficulties in transferring well-known sticky notes properties into digital counterpart or augmenting physical notes digitally in hybrid notes. The chapter covers technical issues with digitally mediated sticky notes used for collaboration. In doing so, it draws from previous work a summary of physical and no-frills digital sticky notes as they were used and analyzed in collaborative situations between two designers. It presents also the no-frills technological solution, DigNote in order to further discuss the space between the physical and the digital as the starting point for exploring hybrid sticky notes. The chapter uses a use scenario and study setup to address creative collaboration between pairs of designers, hence motivating the presented work on hybrid sticky notes. We present this further step, toward HyNote, a hybrid system. HyNote constitutes the main addition to our past work, and it is in …",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15199076040767925948&as_sdt=5"
			}
		}
	},
	{
		"id": 46,
		"title": "Developing hand-worn input and haptic support for real-world target finding",
		"pdf": {
			"host": null,
			"link": "https://link.springer.com/article/10.1007/s00779-018-1180-z"
		},
		"data": {
			"authors": [
				"Yi-Ta Hsieh",
				"Antti Jylhä",
				"Valeria Orso",
				"Salvatore Andolina",
				"Eve Hoggan",
				"Luciano Gamberini",
				"Giulio Jacucci"
			],
			"year": "2019",
			"publication_date": "Feb",
			"journal": "Personal and Ubiquitous Computing",
			"volume": "23",
			"issue": "1",
			"pages": "117-132",
			"publisher": "Springer London",
			"description": "Locating places in cities is typically facilitated by handheld mobile devices, which draw the visual attention of the user on the screen of the device instead of the surroundings. In this research, we aim at strengthening the connection between people and their surroundings through enabling mid-air gestural interaction with real-world landmarks and delivering information through audio to retain users’ visual attention on the scene. Recent research on gesture-based and haptic techniques for such purposes has mainly considered handheld devices that eventually direct users’ attention back to the devices. We contribute a hand-worn, mid-air gestural interaction design with directional vibrotactile guidance for finding points of interest (POIs). Through three design iterations, we address aspects of (1) sensing technologies and the placement of actuators considering users’ instinctive postures, (2) the feasibility of …",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2662457460862458733&as_sdt=5"
			}
		}
	},
	{
		"id": 47,
		"title": "Crossmodal combinations: using piezo-electric, vibrotactile and audio feedback",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://www.researchgate.net/profile/Dik_Hermes/publication/238608024_Perception_of_rubbing_sounds/links/5582ced108aeab1e46686322.pdf#page=33"
		},
		"data": {
			"authors": [
				"Eve Hoggan",
				"Stephen Brewster",
				"Topi Kaaresoja"
			],
			"year": "2008",
			"journal": "3rd International Haptic and Auditory Interaction Design Workshop",
			"pages": "33",
			"description": "In this paper we introduce intramodal tactile combinations where two different types of tactile feedback are presented simultaneously using different actuators and the use of interchangeable audio/tactile feedback using CrossTrainer, a fully crossmodal mobile touchscreen application.",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14763101291298774442&as_sdt=5"
			}
		}
	},
	{
		"id": 48,
		"title": "Crossmodal interaction: using audio or tactile displays in mobile devices",
		"pdf": {
			"host": "[PDF] from springer.com",
			"link": "https://link.springer.com/chapter/10.1007/978-3-540-74800-7_54"
		},
		"data": {
			"authors": [
				"Eve Hoggan"
			],
			"year": "2007",
			"publication_date": "Sept 10",
			"conference": "IFIP Conference on Human-Computer Interaction",
			"pages": "577-579",
			"publisher": "Springer, Berlin, Heidelberg",
			"description": "Mobile device users can be in a variety of different situations where visual, audio, or tactile feedback is not appropriate. This research aims to investigate the design of auditory/tactile crossmodal icons which can provide an alternative form of output using the most appropriate modality to communicate information. The results of this research will aid designers of mobile displays in creating effective crossmodal cues which require minimal training and provide alternative presentation modalities through which information may be presented if the context requires.",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1312755633673839393&as_sdt=5"
			}
		}
	},
	{
		"id": 49,
		"title": "Crossmodal Interaction with Mobile Devices",
		"pdf": {
			"host": "[PDF] from researchgate.net",
			"link": "https://ieeexplore.ieee.org/abstract/document/1698797/"
		},
		"data": {
			"authors": [
				"Eve E Hoggan",
				"Stephen A Brewster"
			],
			"year": "2006",
			"publication_date": "Sept 4",
			"conference": "Visual Languages and Human-Centric Computing (VL/HCC'06)",
			"pages": "234-235",
			"publisher": "IEEE",
			"description": "This paper describes an alternative form of interaction for mobile devices using crossmodal output. These crossmodal displays allow alternative senses such as hearing and touch to be used to perceive information normally presented to the visual modality. Initial experiments show that roughness and spatial location can be perceived as equivalent in both the auditory and tactile domain. This paper discusses how crossmodal displays can be constructed using the results from these experiments and the benefits they bring to mobile human computer interfaces",
			"citations": {
				"total": "1",
				"link": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10026152963549351444&as_sdt=5"
			}
		}
	},
	{
		"id": 50,
		"title": "Deformation Techniques for Shape Changing Interfaces",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/3411763.3451622"
		},
		"data": {
			"authors": [
				"Anke van Oosterhout",
				"Eve Hoggan"
			],
			"year": "2021",
			"publication_date": "May 8",
			"book": "Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems",
			"pages": "1-7",
			"description": "Since the introduction of shape changing interfaces, research in the field has contributed a number of taxonomies to classify shape changing interfaces according to different characteristics, including shape, interaction mapping, material, actuation, and information affordances, in an attempt to grasp the diversity of these interfaces in terms of design and information. However, to our knowledge there exists no classifications of input techniques that are used to deform shape changing interfaces through physical interaction. The interaction affordances provided by shape changing interfaces are important for interaction design and interaction mapping. The work presented here aims to analyse how deformable properties in shape changing interfaces are related to deformation techniques, in order to provide a first step towards the development of design guidelines for physical interaction with shape changing interfaces …"
		}
	},
	{
		"id": 51,
		"title": "Facilitating Flexible Force Feedback Design with Feelix",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/abs/10.1145/3382507.3418819"
		},
		"data": {
			"authors": [
				"Anke van Oosterhout",
				"Miguel Bruns",
				"Eve Hoggan"
			],
			"year": "2020",
			"publication_date": "Oct 21",
			"book": "Proceedings of the 2020 International Conference on Multimodal Interaction",
			"pages": "184-193",
			"description": "In the last decade, haptic actuators have improved in quality and efficiency, enabling easier implementation in user interfaces. One of the next steps towards a mature haptics field is a larger and more diverse toolset that enables designers and novices to explore with the design and implementation of haptic feedback in their projects. In this paper, we look at several design projects that utilize haptic force feedback to aid interaction between the user and product. We analysed the process interaction designers went through when developing their haptic user interfaces. Based on our insights, we identified requirements for a haptic force feedback authoring tool. We discuss how these requirements are addressed by'Feelix', a tool that supports sketching and refinement of haptic force feedback effects."
		}
	},
	{
		"id": 52,
		"title": "the Very Particular",
		"pdf": {
			"host": null,
			"link": "https://dl.acm.org/doi/pdf/10.1145/3301428#page=37"
		},
		"data": {
			"authors": [
				"Olav W Bertelsen",
				"Susanne Bødker",
				"Eva Eriksson",
				"Eve Hoggan",
				"Jo Vermeulen"
			],
			"year": "2019",
			"publication_date": "Jan",
			"journal": "Call for Nominations",
			"volume": "26",
			"pages": "35",
			"description": "In this article, we discuss HCI research that does not aim for universal or generic solutions, but rather focuses on addressing the particular challenges of particular people in particular situations or activities. We clarify what we mean by design and research for the very particular with examples from industry and academic research, highlight benefits and potential problems, discuss our suggestions, and conclude with a list of open questions for HCI researchers to consider. The discussion presented here is a result of a series of debates at the Center for Participatory IT at Aarhus"
		}
	},
	{
		"id": 53,
		"title": "Boxer",
		"pdf": {
			"host": null,
			"link": "https://aaltodoc.aalto.fi/handle/123456789/33856"
		},
		"data": {
			"authors": [
				"Byungjoo Lee",
				"Qiao Deng",
				"Eve Hoggan",
				"Antti Oulasvirta"
			],
			"year": "2017",
			"publication_date": "Nov 3",
			"journal": "International Conference on Multimodal Interaction",
			"description": "Virtual collision techniques are interaction techniques for invoking discrete events in a virtual scene, e.g. throwing, pushing, or pulling an object with a pointer. The conventional approach involves detecting collisions as soon as the pointer makes contact with the object. Furthermore, in general, motor patterns can only be adjusted based on visual feedback. The paper presents a multimodal technique based on the principle that collisions should be aligned with the most salient sensory feedback. Boxer (1) triggers a collision at the moment where the pointer's speed reaches a minimum after first contact and (2) is synchronized with vibrotactile stimuli presented to the hand controlling the pointer. Boxer was compared with the conventional technique in two user studies (with temporal pointing and virtual batting). Boxer improved spatial precision in collisions by 26.7% while accuracy was compromised under some task conditions. No difference was found in temporal precision. Possibilities for improving virtual collision techniques are discussed."
		}
	},
	{
		"id": 54,
		"title": "‘Heads up’interaction: glasgow university multimodal research",
		"pdf": {
			"host": null,
			"link": "http://scholar.google.com/scholar?cluster=4695140925854657273&hl=en&oi=scholarr"
		},
		"data": {
			"authors": [
				"Eve Hoggan"
			]
		}
	}
]